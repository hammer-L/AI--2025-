{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a14af2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linear_layer(x, w, b):\n",
    "    out = x @ w + b\n",
    "    return out\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"\n",
    "    对输入张量 x 执行元素级的 ReLU (Rectified Linear Unit) 操作。\n",
    "    公式为: f(x) = max(0, x)\n",
    "    \"\"\"\n",
    "    # ===== 在此实现 =====\n",
    "    # pass\n",
    "    return np.maximum(0, x)\n",
    "    \n",
    "\n",
    "def flatten(x):\n",
    "    \"\"\"\n",
    "    将一个四维张量 (N, C, H, W) 展平为一个二维张量 (N, C*H*W)。\n",
    "    N 是批量大小，需要保持不变。\n",
    "    \"\"\"\n",
    "    # ===== 在此实现 =====\n",
    "    N, C, H, W = x.shape\n",
    "    return x.reshape(N, C*H*W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18f2c323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear2: [[ 2.5]\n",
      " [ 1.5]\n",
      " [ 0.5]\n",
      " [-0.5]\n",
      " [-1.5]]\n",
      "relu2: [[2.5]\n",
      " [1.5]\n",
      " [0.5]\n",
      " [0. ]\n",
      " [0. ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[-2], [-1], [0], [1], [2]])\n",
    "\n",
    "w1, b1 = np.array([[2]]), np.array([-1])\n",
    "w2, b2 = np.array([[-1]]), np.array([0.5])\n",
    "\n",
    "linear1 = linear_layer(x, w1, b1)\n",
    "linear2 = linear_layer(x, w2, b2)\n",
    "relu1 = relu(linear1)\n",
    "relu2 = relu(linear2)\n",
    "print ('linear2:', linear2)\n",
    "print ('relu2:', relu2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc224a",
   "metadata": {},
   "source": [
    "**分析与思考：**\n",
    "\n",
    "1. **观察与对比**：对比B中relu前和relu后的值，`relu` 函数具体做了什么？对比A和B的最终输出，它们的输出模式有何根本不同？\n",
    "2. **总结**：通过本次实验，请用你自己的话讲解，为什么非线性激活函数是构建深度神经网络的**必需品**？\n",
    "3. **扩展思考**：本题中我们基本没有涉及`Flatten`层，仅将其实现以为后续使用，`Flatten` 层虽然简单，但它在CNN中通常扮演着什么角色？\n",
    "\n",
    "**回答：**\n",
    "1. 观察与对比:ReLU 将所有负数部分直接截断为 0，仅保留正数部分，并保持其原值。\n",
    "2. 将神经网络变为非线性网络，不然加再多神经元都是线性的。\n",
    "3. 把多维特征展平为一维向量 (C*H*W)，从而可以输入到全连接层中，为分类或回归做准备。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71236c",
   "metadata": {},
   "source": [
    "参数灾难**：假设输入一张 `100x100` 的单通道图，一个全连接层需要多少权重才能仅仅让**一个输出神经元**连接到所有输入像素？作为对比，一个 `3x3` 的卷积核总共需要多少个权重参数？\n",
    "\n",
    "答：（1）10001个 （2）10个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd9174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, w, b, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    使用循环实现一个朴素的 2D 卷积操作。\n",
    "    \"\"\"\n",
    "    # ===== 在此实现 =====\n",
    "    N, C, H, W = x.shape\n",
    "    F, _, KH, KW = w.shape\n",
    "    \n",
    "    if padding > 0:\n",
    "        x_padded = np.pad(x, ((0,0),(0,0),(padding,padding),(padding,padding)), mode='constant')\n",
    "    else:\n",
    "        x_padded = x\n",
    "    \n",
    "    H_out = (H + 2*padding - KH) // stride + 1\n",
    "    W_out = (W + 2*padding - KW)//stride + 1\n",
    "    \n",
    "    out = np.zeros((N, F, H_out, W_out))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for f in range(F):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    h_start = i * stride\n",
    "                    w_start = j * stride\n",
    "                    h_end = h_start + KH\n",
    "                    w_end = w_start + KW\n",
    "                    # 卷积：对应通道相乘再累加\n",
    "                    out[n, f, i, j] = np.sum(\n",
    "                        x_padded[n, :, h_start:h_end, w_start:w_end] * w[f, :, :, :]\n",
    "                    ) + b[f]\n",
    "    \n",
    "    return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e49a5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_centered1 = np.array([[\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 1, 0, 0],\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0]\n",
    "    ]], dtype=np.float32).reshape(1, 1, 5, 5)\n",
    "\n",
    "w = np.array([\n",
    "    [0,1,0],\n",
    "    [1,1,1],\n",
    "    [0,1,0]\n",
    "], dtype=np.float32).reshape(1,1,3,3)\n",
    "\n",
    "b = [0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2844f5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[2., 2., 2.],\n",
       "         [2., 5., 2.],\n",
       "         [2., 2., 2.]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = conv2d(image_centered1, w, b)\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1298a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 1.],\n",
       "         [0., 2., 2.],\n",
       "         [1., 2., 5.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_centered2 = np.array([[\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 1, 0],\n",
    "        [0, 0, 1, 1, 1],\n",
    "        [0, 0, 0, 1, 0]\n",
    "    ]], dtype=np.float32).reshape(1, 1, 5, 5)\n",
    "conv2 = conv2d( image_centered2, w, b)\n",
    "conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2522b6f7",
   "metadata": {},
   "source": [
    "**局部性：** 卷积核每次只能看见它大小的这块区域，而不是一次看到整张图\n",
    "\n",
    "**平移不变性：** 因为是卷积核在图片上横向滑动，并且每次滑动都与前面的参数是共享的，图片上的特征就算平移了也只会改变提取到后面感受野的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf09c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_pool1 [[[[5.]]]]\n",
      "max_pool2 [[[[2.]]]]\n",
      "mean_pool1 [[[[2.75]]]]\n",
      "mean_pool2 [[[[0.5]]]]\n"
     ]
    }
   ],
   "source": [
    "def max_pool2d(x, kernel_size=2, stride=2):\n",
    "    # ===== 在此实现 =====\n",
    "    N, F, H, W = x.shape\n",
    "    \n",
    "    H_out = (H  - kernel_size) // stride + 1\n",
    "    W_out = (W - kernel_size)//stride + 1\n",
    "    \n",
    "    out = np.zeros((N, F, H_out, W_out))\n",
    "\n",
    "    for n in range(N):\n",
    "        for f in range(F):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    h_start = i * stride\n",
    "                    w_start = j * stride\n",
    "                    h_end = h_start + kernel_size\n",
    "                    w_end = w_start + kernel_size\n",
    "                    window = x[n, f, h_start:h_end, w_start:w_end]\n",
    "                    out[n,f,i,j] = np.max(window)\n",
    "    return out\n",
    "\n",
    "def mean_pool2d(x, kernel_size=2, stride=2):\n",
    "    # ===== 在此实现 =====\n",
    "    N, F, H, W = x.shape\n",
    "    \n",
    "    H_out = (H  - kernel_size) // stride + 1\n",
    "    W_out = (W - kernel_size)//stride + 1\n",
    "    \n",
    "    out = np.zeros((N, F, H_out, W_out))\n",
    "\n",
    "    for n in range(N):\n",
    "        for f in range(F):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    h_start = i * stride\n",
    "                    w_start = j * stride\n",
    "                    h_end = h_start + kernel_size\n",
    "                    w_end = w_start + kernel_size\n",
    "                    window = x[n, f, h_start:h_end, w_start:w_end]\n",
    "                    out[n,f,i,j] = np.mean(window)\n",
    "    return out\n",
    "\n",
    "pool1 = max_pool2d(conv1)\n",
    "pool2 = max_pool2d(conv2)\n",
    "mean_pool1 = mean_pool2d(conv1)\n",
    "mean_pool2 = mean_pool2d(conv2)\n",
    "print ('max_pool1', pool1)\n",
    "print ('max_pool2', pool2)\n",
    "print ('mean_pool1',mean_pool1)\n",
    "print ('mean_pool2',mean_pool2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d59ba76",
   "metadata": {},
   "source": [
    "**分析与思考：**\n",
    "\n",
    "1. **稳健性**：对比两个特征图的输出，这个实验如何证明了最大池化层能提供一定程度的“平移不变性”？\n",
    "2. **降维与效率**：对比池化前后的特征图尺寸，你认为池化层对整个网络的计算效率有什么好处？\n",
    "3. **机制对比**：请思考，如果将最大池化其换成“平均池化”（Average Pooling），实验结果会有何不同？在筛选特征方面，最大池化和平均池化各自的倾向是什么？\n",
    "\n",
    "**回答：**\n",
    "1.最大池化取局部窗口内的最大值，只要特征仍在池化窗口内移动，输出值通常不变。但有些特殊情况，比如明显的特征在边缘没池化到，或者被更明显的特征掩盖了，可能会影响平移不变性。\n",
    "\n",
    "2.后续卷积层输入更小，但总体前向传播/反向传播计算量下降。\n",
    "\n",
    "3.**最大池化:** 保留局部最显著的特征（边缘、角点）,常应用在分类/检测时，强调显著特征。\n",
    "\n",
    "**平均池化：** 平滑局部特征，强调平均趋势，但可能丢失局部高响应信息，更适合降噪、平滑特征或生成任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fac0e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "# (在此之前应有已实现的 conv2d, relu, max_pool2d, flatten,linear_layer函数)\n",
    "# 固定随机种子，保证权重初始化一致\n",
    "np.random.seed(114514)\n",
    "\n",
    "def softmax(logits):\n",
    "    \"\"\"\n",
    "    实现Softmax函数\n",
    "    \"\"\"\n",
    "    # ===== 在此实现 =====\n",
    "    logits = np.array(logits)\n",
    "    logits = logits - np.max(logits, axis=1, keepdims=True)\n",
    "    exp_scores = np.exp(logits)\n",
    "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    \n",
    "\n",
    "# --- MNIST 数据集读取函数 ---\n",
    "def read_images(filename):\n",
    "    \"\"\"\n",
    "    读取MNIST图像文件\n",
    "    参数:\n",
    "      filename: MNIST图像文件路径\n",
    "    返回:\n",
    "      images: 图像数组列表\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "        \n",
    "        image_data = array(\"B\", file.read())\n",
    "        \n",
    "    images = []\n",
    "    for i in range(size):\n",
    "        img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "        img = img.reshape(rows, cols)\n",
    "        images.append(img)\n",
    "    \n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2901b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyCNN_for_MNIST:\n",
    "# ===== 在此实现你的类 =====\n",
    "    def  __init__(self):\n",
    "        self.conv_W = np.random.randn(4, 1, 3, 3) * 0.01\n",
    "        self.conv_b = np.zeros(4)\n",
    "        \n",
    "        # Linear: 4*14*14 = 784, 输出 10 类\n",
    "        self.fc_W = np.random.randn(4*14*14, 10) * 0.01\n",
    "        self.fc_b = np.zeros(10) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = conv2d(x, self.conv_W, self.conv_b, stride=1, padding=1)\n",
    "        out = relu(out)\n",
    "        out = max_pool2d(out, kernel_size=2, stride=2)\n",
    "        out = flatten(out)\n",
    "        logits = linear_layer(out, self.fc_W, self.fc_b)\n",
    "        probs = softmax(logits)\n",
    "        \n",
    "        return logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1df38c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor Shape: (1, 1, 28, 28)\n",
      "Logits shape: (1, 10) Probs shape: (1, 10)\n",
      "\n",
      "Logits: [ 0.00353601 -0.00597512 -0.01245221  0.00474773 -0.00172211  0.00710951\n",
      "  0.00555682 -0.00088172  0.00028607 -0.00289982]\n",
      "Probs: [0.10037968 0.09942948 0.09878755 0.10050138 0.09985325 0.10073903\n",
      " 0.10058273 0.0999372  0.10005398 0.09973572]\n",
      "\n",
      "Checksum logits sum: -0.0026948397355464285\n",
      "Checksum probs sum: 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "from array import array\n",
    "\n",
    "# --- 测试脚本 ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 设置 MNIST 测试集文件路径\n",
    "    # !! 请将此路径修改为你自己的文件路径\n",
    "    mnist_test_file = r'E:\\0workspace\\AI派2025招新第一轮测试\\mnist\\t10k-images.idx3-ubyte'\n",
    "\n",
    "    if not os.path.exists(mnist_test_file):\n",
    "        print(f\"错误：找不到 MNIST 测试集文件 '{mnist_test_file}'\")\n",
    "    else:\n",
    "        # 2. 加载所有测试图像\n",
    "        test_images = read_images(mnist_test_file)\n",
    "        # 3. 选取第一张图像作为测试输入\n",
    "        first_test_image = test_images[0]\n",
    "        # 4. 预处理图像\n",
    "        input_tensor = (first_test_image.astype(np.float32) / 255.0 - 0.5) * 2.0\n",
    "        input_tensor = np.expand_dims(input_tensor, axis=(0, 1))\n",
    "        # 5. 实例化模型并执行前向传播\n",
    "        model = TinyCNN_for_MNIST()\n",
    "        logits, probs = model.forward(input_tensor)\n",
    "\n",
    "        print(\"Input Tensor Shape:\", input_tensor.shape)\n",
    "        print(\"Logits shape:\", logits.shape, \"Probs shape:\", probs.shape)\n",
    "        np.set_printoptions(precision=8, suppress=False)\n",
    "        print(\"\\nLogits:\", logits[0])\n",
    "        print(\"Probs:\", probs[0])\n",
    "        print(\"\\nChecksum logits sum:\", float(np.sum(logits)))\n",
    "        print(\"Checksum probs sum:\", float(np.sum(probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a4bd74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
