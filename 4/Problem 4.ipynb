{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af7dd55",
   "metadata": {},
   "source": [
    "### 小题1：概念与公式阐述\n",
    "\n",
    "1. **词嵌入（Word Embedding）**：\n",
    "   - 请解释词嵌入的定义及其作用。\n",
    "   - 说明词嵌入如何解决传统词表示方法的局限性。\n",
    "   - 举例说明一种常见的词嵌入模型及其特点。\n",
    "2. **多头自注意力（Multi-Head Self-Attention）**：\n",
    "   - 说明多头自注意力的核心思想\n",
    "   - 写出缩放点积注意力（Scaled Dot-Product Attention）的计算公式，并解释公式中各参数的含义。\n",
    "   \n",
    "### 回答1：\n",
    "- 定义：词嵌入是一种将自然语言中的词语表示为低维、稠密的连续向量的方法。这些向量在空间中能够捕捉词语之间的语义和语法关系。 作用：让计算机能够“理解”词的语义（相似的词有相近的向量）。将原本离散的符号（词）转换为模型可计算的数值形式。减少特征维度，提升训练效率和泛化能力。\n",
    "- 传统方法主要是 One-Hot 编码 和 词袋模型（Bag of Words, BOW），它们的局限性：维度过高：词表中有多少个词，向量就有多长（通常上万或更多）。稀疏性强：大多数维度都是 0，不利于模型学习。缺乏语义信息：例如 One-Hot 中，“猫”和“狗”的向量完全正交，看不出它们的相似性。\n",
    "- Word2Vec（Google，2013）特点：训练高效，能在大规模语料上快速学习。能捕捉词之间的语义关系，向量空间结构具有良好的可解释性。训练得到的词向量可以迁移到下游任务中作为预训练词向量使用。\n",
    "\n",
    "### 回答2：\n",
    "- 将输入的向量通过不同的线性映射拆分成 多个子空间（多个头，heads）；每个头在子空间上独立计算注意力（即学习不同的相关性模式，比如语法关系、语义关系等）；最后将所有头的输出拼接（concatenate）起来，再做一次线性变换得到最终结果。\n",
    "- $Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$\n",
    "\n",
    "Q (Query)：查询矩阵,K (Key)：键矩阵，V (Value)：值矩阵，$\\sqrt{d_k}$缩放因子,softmax：归一化操作."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fddbf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(114514)\n",
    "\n",
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    \n",
    "    N, K, M = query.shape\n",
    "    output = np.zeros_like(query)\n",
    "    attention_weights = np.zeros((N, K, K))\n",
    "    \n",
    "    for n in range(N):\n",
    "        scores = query[n] @ key[n].T / np.sqrt(M) # (K, K)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = np.where(mask[n], scores, -1e9)\n",
    "            \n",
    "        scores_exp = np.exp(scores - np.max(scores, axis=-1, keepdims=True))\n",
    "        att_weights = scores_exp / np.sum(scores_exp, axis=-1, keepdims=True)\n",
    "        attention_weights[n] = att_weights\n",
    "        output[n] = att_weights @ value[n]\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b3a3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention(embed_size, num_heads, x, mask=None):\n",
    "    \n",
    "    N, K, D = x.shape\n",
    "    head_dim = D // num_heads\n",
    "    assert D % num_heads == 0\n",
    "    \n",
    "    # 初始化\n",
    "    W_Q = np.random.randn(D,D)\n",
    "    W_K = np.random.randn(D,D)\n",
    "    W_V = np.random.randn(D,D)\n",
    "    W_O = np.random.randn(D,D)\n",
    "    \n",
    "    output = np.zeros((N, K, D))\n",
    "    all_weights = np.zeros((N, num_heads, K, K))\n",
    "    \n",
    "    for n in range(N):\n",
    "        Q = x[n] @ W_Q # (K, D)\n",
    "        K = x[n] @ W_K\n",
    "        V = x[n] @ W_V\n",
    "        \n",
    "        head_outputs = []\n",
    "        for h in range(num_heads):\n",
    "            Q_h = Q[:, h*head_dim: (h+1)*head_dim]  # (K, head_dim)\n",
    "            K_h = K[:, h*head_dim: (h+1)*head_dim]\n",
    "            V_h = V[:, h*head_dim: (h+1)*head_dim]\n",
    "\n",
    "            out_h, attn_h = scaled_dot_product_attention(\n",
    "                Q_h[None, :, :],\n",
    "                K_h[None, :, :],\n",
    "                V_h[None, :, :],\n",
    "                mask\n",
    "            )\n",
    "            # 去掉 batch 维\n",
    "            out_h = out_h[0]\n",
    "            attn_h = attn_h[0]\n",
    "            \n",
    "            head_outputs.append(out_h)\n",
    "            all_weights[n,h] = attn_h\n",
    "        \n",
    "        head_outputs = np.concatenate(head_outputs, axis=-1)\n",
    "        output[n] = head_outputs @ W_O\n",
    "    \n",
    "    return output, all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a849cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 128) (10, 8, 20, 20)\n",
      "[ -64.9601117   -38.18690465  -49.38122126    1.33917629  -55.27862891\n",
      " -121.93890998 -107.96320283 -141.02273922   33.95973751  -29.02877682] [5.20961722e-145 2.71639176e-113 1.79900964e-097 2.92622563e-101\n",
      " 1.92231371e-060 8.65088333e-081 1.56849882e-122 8.85718800e-066\n",
      " 3.92946177e-186 1.73323736e-033]\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "batch_size = 10\n",
    "seq_len = 20\n",
    "embed_size = 128\n",
    "num_heads = 8\n",
    "input = np.random.randn(batch_size, seq_len, embed_size) \n",
    "output, weights = multi_head_attention(embed_size, num_heads, input)\n",
    "\n",
    "print(output.shape, weights.shape)\n",
    "print(output[0][0][:10], weights[0][0][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cecf5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"基于PyTorch的多头自注意力实现\"\"\"\n",
    "    def __init__(self, embed_size, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        assert embed_size % num_heads == 0\n",
    "        self.head_dim = embed_size // num_heads\n",
    "        \n",
    "        self.W_Q = nn.Linear(embed_size, embed_size)\n",
    "        self.W_K = nn.Linear(embed_size, embed_size)\n",
    "        self.W_V = nn.Linear(embed_size, embed_size)\n",
    "        \n",
    "        self.W_O = nn.Linear(embed_size, embed_size)\n",
    "        \n",
    "        \n",
    "        def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "            \n",
    "            N, K, M = Q.shape\n",
    "            weights = torch.bmm(Q, K.transpose(1,2)) / (M ** 0.5)\n",
    "            \n",
    "            if mask is not None:\n",
    "                weights = weights.masked_fill(mask, -1e9)\n",
    "                \n",
    "            weights_softmax = F.softmax(weights, axis=-1)\n",
    "            y = torch.bmm(weights_softmax, value)\n",
    "            \n",
    "            return y, weights_softmax\n",
    "            \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "\n",
    "        N, K, M = query.shape\n",
    "        \n",
    "        Q = self.W_Q(query)  # (N, seq_len, embed_size)\n",
    "        K = self.W_K(key)\n",
    "        V = self.W_V(value)\n",
    "        \n",
    "        Q = Q.view(N, K, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(N, K, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(N, K, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        out, attention = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        out = out.transpose(1, 2).contiguous().view(N, seq_len, self.embed_size)\n",
    "        \n",
    "        out = self.W_O(out)\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "788c476a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 128) (10, 8, 20, 20)\n",
      "[-196.87236493  130.3874899  -112.67200377  111.43094804   65.09261902\n",
      "   24.64296057 -162.82767893  147.82880116  -29.39549941  210.36298327] [7.86194491e-103 2.09418313e-038 4.83344845e-079 6.58217747e-033\n",
      " 1.48395612e-013 9.99990519e-001 3.20118328e-034 1.82026292e-068\n",
      " 7.31896795e-107 1.15190036e-085]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "seq_len = 20\n",
    "embed_size = 128\n",
    "num_heads = 8\n",
    "input = np.random.randn(batch_size, seq_len, embed_size) \n",
    "output, weights = multi_head_attention(embed_size, num_heads, input)\n",
    "\n",
    "print(output.shape, weights.shape)\n",
    "print(output[0][0][:10], weights[0][0][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e28d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
