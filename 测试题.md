# 第一轮测试

​		第一轮测试共有**5**道题目，最大程度的完成这些题目即可，做不出来也不要紧，重要的是让我们看到你的思考！

​		每道题目均有数个小问，一些需要你编程完成，一些需要你进行学习、推导、分析，并记录过程和答案，**请用markdown或者jupyter notebook(推荐)记录你每道题的思考与解答**。

​		我们是以兴趣为导向的团队，本测试不是你用来获得学分或水成绩的课程大作业，我们希望参与测试的人能够在测试中开拓眼界、提高自己，请明确你参加本测试的目的，也请**尊重本测试的每一个参与者**，**禁止一切形式的抄袭行为！**

​		记录时，我们推荐使用jupyter notebook，它可以保存你的代码运行结果，也支持markdown，Typora + LaTeX也是一个很好的组合。当然，如果你认为时间有限，也可以提交其他形式的文档，我们不会因此降低对你的评价，但希望你最终提交的**结果清晰易辨**，不至于带来交流的不便。

​		若有相关疑问可以在群内询问管理员。

## 问题一与问题二的背景：MBA Admission dataset, Class 2025

### About Dataset

1. Data Source:
Synthetic data generated from the Wharton Class of 2025's statistics.

2. Meta Data:
- application_id: Unique identifier for each application
- gender: Applicant's gender (Male, Female)
- international: International student (TRUE/FALSE)
- gpa: Grade Point Average of the applicant (on 4.0 scale)
- major: Undergraduate major (Business, STEM, Humanities)
- race: Racial background of the applicant (e.g., White, Black, Asian, Hispanic, Other / null: international student)
- gmat: GMAT score of the applicant (800 points)
- work_exp: Number of years of work experience (Year)
- work_industry: Industry of the applicant's previous work experience (e.g., Consulting, - Finance, Technology, etc.)
- admission: Admission status (Admit, Waitlist, Reject)

### Problem description

Your goal is to predict the admission status based on other features. The dataset has already been split into train.csv and test.csv



## 1 数据处理

*出题人：谭博涵*

​	真实世界的数据往往包含缺失值、异常值和一些无法直接用于机器学习模型的特征，数据预处理通常是必不可少的环节。这一题我们希望你利用pandas,numpy,matplotlib,完成以下要求：

### 具体要求

- 给出训练集数值型变量的count、mean、std、min、mid、max的统计特征，给出训练集非数值型变量的count、unique、value的表
- 对缺失值进行合适的处理，要求至少使用两种方法完成缺失值的补充；
- 将分类属性进行OneHot编码，你需要对Gender进行标签编码，对international for MBA进行除所述两个编码外的任意编码，其余需要进行编码的数据采取one-hot编码；
- 对数值属性进行必要的操作，如归一化处理等；
- 可视化分析数据，展示数据分布，发现规律；
- 除此之外，你还可以进行必要的数据探索，如计算相关性等等。

### 提示

参考资料

- （美）麦金尼（McKinney W.）著；唐学韬译. 利用Python进行数据分析 [M]. 北京：机械工业出版社, 2016.01.

- [NumPy官方网站](https://numpy.org)
- 机器学习实战：基于Scikit-Learn和TensorFlow

## 2 分类

*出题人：谢悦晋*

​	在后续的问题中，你可能需要使用各种分类方法解决问题：

### 具体要求

1. 本题需要你分别用线性回归和逻辑回归对该数据集分类，请给出在训练集和测试集上的准确率。
2. 本题需要你用MLP对该数据集分类，请给出在训练集和测试集上的准确率，可以使用的工具库：numpy, scipy, sklearn，你可以直接调用库实现好的模型方法
```python
# hidden_dim
[input_dim, 128], ReLU()
[128, 256], ReLU()
[256, output_dim]

# params
lr = 0.0001
epoch = 50
batch = 64
```
3. 同上，请使用torch库完成上述2.2的任务。为何两个库的结果有所差异？除此之外，你应该会发现测试集和训练集的准确率有很大的差异，尝试解释这种差异的原因
4. 2.2的基础上，解释激活函数的作用，比较没有激活函数、Relu、Sigmoid作为激活函数时的效果
5. 对特征变量进行一定的取舍、分组等操作，是否能提升MLP的性能呢？给出你尝试的过程
6. （选做）给出本道题MLP模型反向传播的公式推导(默认激活函数ReLU)，你可以手写，也可以尝试用LaTeX代码来写。



- 参考资料：李航.统计学习方法[M].北京:清华大学出版社,2019.5.1

## 3 CNN

*出题人：赵宗霖*

卷积神经网络（CNN）是深度学习在计算机视觉领域的基石。它通过模仿人类视觉的工作方式，利用卷积层（Conv2d）提取局部特征，池化层（Pooling）进行特征降维和信息筛选，最后通过全连接层（Linear）将特征映射到最终的分类结果。

本次实践中，我们**将用最基础的 Python 库 NumPy** 来亲手实现这些核心组件。你将深入理解数据在网络中是如何流动的（前向传播），以及张量（Tensor）的形状在每一层之后是如何变化的。**本题目虽然每小问看着比较长，但是并不难并且大部分内容为探索性的实验已给出的脚本，仅有部分内容需要补充（**

**题目最后有参考资料以供学习，如果没有基础，我们推荐你先阅读学习资料后再做题，这将对题目有更深刻的理解**


### 小题1: 背景问题

一个最简单的神经网络由线性层构成。但如果仅仅堆叠线性层，我们能否让网络学会识别复杂的非线性图案（比如曲线）？本题将通过构建和对比，让你发掘一个看似微小的改动——引入ReLU激活函数——是如何赋予网络全新的表达能力的。

**任务**：请在下方提供的函数框架中，完成`linear_layer`、 `relu` 和 `flatten` 这三个核心算子的实现。

```python
import numpy as np

def linear_layer(x, w, b):
    pass

def relu(x):
    """
    对输入张量 x 执行元素级的 ReLU (Rectified Linear Unit) 操作。
    公式为: f(x) = max(0, x)
    """
    # ===== 在此实现 =====
    pass

def flatten(x):
    """
    将一个四维张量 (N, C, H, W) 展平为一个二维张量 (N, C*H*W)。
    N 是批量大小，需要保持不变。
    """
    # ===== 在此实现 =====
    pass
```

**探究指引：**

在你完成了上述函数实现后，请按照以下步骤，进行一次对比实验：

1. **创建输入数据**：
首先，定义一个简单的 NumPy 数组作为我们两个微型网络的输入。这个输入代表了一组从负到正的连续值。
`x = np.array([[-2], [-1], [0], [1], [2]])`
2. **设定网络权重**：
   为了保证结果的一致性，我们使用固定的权重和偏置。请定义以下变量：
   `w1, b1 = np.array([[2]]), np.array([-1])`
   
    `w2, b2 = np.array([[-1]]), np.array([0.5])`
   
3. **模拟“纯线性网络 A”**：
计算一个两层线性网络的前向传播结果
4. **模拟“引入非线性的网络 B”**：
在两层线性网络之间插入你实现的 `relu` 函数，并计算其结果。

**分析与思考：**

1. **观察与对比**：对比B中relu前和relu后的值，`relu` 函数具体做了什么？对比A和B的最终输出，它们的输出模式有何根本不同？
2. **总结**：通过本次实验，请用你自己的话讲解，为什么非线性激活函数是构建深度神经网络的**必需品**？
3. **扩展思考**：本题中我们基本没有涉及`Flatten`层，仅将其实现以为后续使用，`Flatten` 层虽然简单，但它在CNN中通常扮演着什么角色？


### 小题2: CNN的背景

**核心困境**：若要用一个全连接层识别图像中的局部特征（如一只猫的耳朵），其“全局连接”的设计会导致两个致命问题：1) 参数量随图像尺寸急剧爆炸；2) 模型不具备平移不变性，即在A位置学会的特征，无法直接用于识别出现在B位置的相同特征。

#### 任务

**思考:**

- **参数灾难**：假设输入一张 `100x100` 的单通道图，一个全连接层需要多少权重才能仅仅让**一个输出神经元**连接到所有输入像素？作为对比，一个 `3x3` 的卷积核总共需要多少个权重参数？

##### **代码实现与引导实验**

**任务**：

1. **实现核心算法**：在下方框架中，完成 `conv2d` 函数的实现。
2. **运行引导实验**：请你查看给出的示例代码，并将其补全，完成以下两个阶段的实验
    - **阶段一**：验证卷积核作为特征检测器的有效性。
    - **阶段二**：通过移动图案，探索卷积操作的“平移不变性”。

```python
import numpy as np

def conv2d(x, w, b, stride=1, padding=0):
    """
    使用循环实现一个朴素的 2D 卷积操作。
    """
    # ===== 在此实现 =====
    pass

if __name__ == "__main__":
    #阶段一: 验证特征检测
    # 1. 定义一个 5x5 的图像，中心有一个“十字”图案
    image_centered = np.array([[
        [0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0],
        [0, 1, 1, 1, 0],
        [0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0]
    ]], dtype=np.float32).reshape(1, 1, 5, 5)

    # 2. 设计一个 3x3 的卷积核，当它滑过输入图像时，如果它对应的图像区域与十字图案完全一致，它计算出的结果应该是最大的。
    
    # 3. 执行卷积，观察输出

    # 阶段二: 平移不变性
    # 1. 创建一个新图像，将“十字”图案向右下方平移一格
    image_centered = np.array([[
        [0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0],
        [0, 0, 1, 1, 1],
        [0, 0, 0, 1, 0]
    ]], dtype=np.float32).reshape(1, 1, 5, 5)
    # 2. 使用完全相同的卷积核进行卷积，并观察输出
```

#### **分析与思考**

请你根据实践结果，用自己的话讲解卷积操作的**局部性**和**平移不变性**

### 小题3: 池化层

**背景问题：**
经过卷积层后，我们得到了包含大量特征信息的特征图。但这些信息可能过于冗余和精细，导致后续计算量巨大，且容易对特征的微小位移过于敏感。池化层如何解决这个问题？

**任务：**

1. **构造数据**：创建一个简单的 `4x4` 特征图，其中包含一个显著的激活模式（可以实现为一个2*2的区域内数值显著高于其他区域）。然后，创建第二个特征图，将同样的激活模式平移1个像素。
2. **代码实现**：完成 `max_pool2d` 函数。
3. **运行实验**：将上述两个特征图分别送入你实现的 `max_pool2d` 函数（使用 `2x2` 窗口，`stride=2`），并仔细对比它们的输出。

**代码实践与探究：**

```python
def max_pool2d(x, kernel_size=2, stride=2):
    # ===== 在此实现 =====
    pass
```

**分析与思考：**

1. **稳健性**：对比两个特征图的输出，这个实验如何证明了最大池化层能提供一定程度的“平移不变性”？
2. **降维与效率**：对比池化前后的特征图尺寸，你认为池化层对整个网络的计算效率有什么好处？
3. **机制对比**：请思考，如果将最大池化其换成“平均池化”（Average Pooling），实验结果会有何不同？在筛选特征方面，最大池化和平均池化各自的倾向是什么？

### 小题4: CNN


**任务**：

1. 回答以下问题：Softmax 函数的输出向量具备什么数学特性？为什么这些特性使它成为多分类问题中理想的输出层激活函数？
2. **实现 `softmax` 函数。**
3. **根据下方的“模型架构”，从零开始编写 `TinyCNN_for_MNIST` 这个类**，包括 `__init__` 构造函数和 `forward` 前向传播方法。
4. 将已提供的mnist数据集`mnist.zip` 解压到目录
5. 利用提供的 MNIST 数据集读取函数，加载 **测试集** 数据，并把其中的**第一张图像**作为输入，送入你亲手实现的模型进行最终验证。

```python
import numpy as np
import gzip
import os

# (在此之前应有已实现的 conv2d, relu, max_pool2d, flatten,linear_layer函数)
# 固定随机种子，保证权重初始化一致
np.random.seed(114514)

def softmax(logits):
    """
    实现Softmax函数。
    """
    # ===== 在此实现 =====
    pass

# --- MNIST 数据集读取函数 ---
def read_images(filename):
    """
    读取MNIST图像文件
    参数:
      filename: MNIST图像文件路径
    返回:
      images: 图像数组列表
    """
    with open(filename, 'rb') as file:
        magic, size, rows, cols = struct.unpack(">IIII", file.read(16))
        if magic != 2051:
            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))
        
        image_data = array("B", file.read())
        
    images = []
    for i in range(size):
        img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])
        img = img.reshape(rows, cols)
        images.append(img)
    
    return images

# =========================================================
# ===== 任务：请根据下面的规约，在此处实现 TinyCNN_for_MNIST 类 =====
# =========================================================
#
# --- 模型架构规约 ---
# 1. 构造函数 `__init__(self)`:
# 架构固定：Conv(1->4, k=3, stride=1, pad=1) -> ReLU -> MaxPool(2x2, s=2) -> Flatten -> Linear(->10 类)
# 2. 前向传播方法 `forward(self, x)`:
#    - 接收一个形状为 (N, 1, 28, 28) 的张量 x。
#    - 按照以下顺序依次调用你实现的算子：
#      Conv2d -> ReLU -> MaxPool2d -> Flatten -> Linear -> Softmax
#    - 返回最终的 logits (Linear层输出) 和 probs (Softmax层输出)。

class TinyCNN_for_MNIST:
# ===== 在此实现你的类 =====
		pass

# --- 测试脚本 ---
if __name__ == "__main__":
    # 1. 设置 MNIST 测试集文件路径
    # !! 请将此路径修改为你自己的文件路径
    mnist_test_file = './t10k-images-idx3-ubyte.gz'

    if not os.path.exists(mnist_test_file):
        print(f"错误：找不到 MNIST 测试集文件 '{mnist_test_file}'")
    else:
        # 2. 加载所有测试图像
        test_images = read_images(mnist_test_file)
        # 3. 选取第一张图像作为测试输入
        first_test_image = test_images[0]
        # 4. 预处理图像
        input_tensor = (first_test_image.astype(np.float32) / 255.0 - 0.5) * 2.0
        input_tensor = np.expand_dims(input_tensor, axis=(0, 1))
        # 5. 实例化模型并执行前向传播
        model = TinyCNN_for_MNIST()
        logits, probs = model.forward(input_tensor)

        print("Input Tensor Shape:", input_tensor.shape)
        print("Logits shape:", logits.shape, "Probs shape:", probs.shape)
        np.set_printoptions(precision=8, suppress=False)
        print("\nLogits:", logits[0])
        print("Probs:", probs[0])
        print("\nChecksum logits sum:", float(np.sum(logits)))
        print("Checksum probs sum:", float(np.sum(probs)))
```

### 小题5: 对比分析 NumPy 实现与 PyTorch 框架（可选）

本题可以在有余力的情况下完成，但是我们推荐你尝试完成该题目。

恭喜你！至此，你已成功用底层代码构建了一个可工作的 CNN。现在，是时候思考一个更深层次的问题了：“我们为什么要使用 PyTorch 这样的高级框架？” 本挑战旨在通过亲手对比，让你深刻体会工业级框架在功能、性能和开发效率上的巨大优势。

**任务指引：**

1. **构建对等模型**：使用 `torch.nn` 模块，搭建一个与 `TinyCNN_for_MNIST` 结构完全一致的 PyTorch 模型。
2. **迁移相同权重**：将 NumPy 版模型中由 `seed=114514` 生成的 `conv_w`, `conv_b`, `fc_w`, `fc_b` 权重，精确地加载到你的 PyTorch 模型中。
3. **进行推理对比**：使用相同的 MNIST 输入图像，分别通过两个模型进行前向传播，并用 `np.allclose()` 验证 `logits` 输出是否在数值精度上高度一致。
4. **完成分析报告**：基于以上实验，深入回答下列分析性问题。

**分析与思考**

1. **功能性对比** ：除了我们实现的版本，PyTorch 的 `nn.Conv2d` 还提供了哪些我们的 NumPy 版本不具备的进阶功能或参数？
2. **性能对比**：为何 PyTorch 的运算速度会比我们手写的 Python `for` 循环快几个数量级？请从底层实现语言、并行计算策略、以及可能的算法优化等角度进行分析。
3. **核心优势对比** ：在你看来，使用 PyTorch 这类框架相对于从零手写，其最根本、最无法替代的优势是什么？

### **推荐学习资源**

#### **1. 深度学习课程与教材**

- **斯坦福大学 CS231n 课程 - Convolutional Neural Networks for Visual Recognition**
    - **简介**：这几乎是计算机视觉领域最经典的深度学习课程。课程笔记详尽地解释了CNN的每一个细节，从业界发展、数学原理，到实际应用。如果你对cnn并没有基础，我强烈建议你阅读该课程笔记的cnn章节。
    - **链接**：
        - [课程官网 (英文)](http://cs231n.stanford.edu/)    [cnn章节](https://cs231n.github.io/convolutional-networks/)
        - [知乎专栏中文翻译](https://zhuanlan.zhihu.com/p/21930884)    [知乎cnn章节](https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit)
- **《动手学深度学习》(Dive into Deep Learning)**
    - **简介**：由许多大佬撰写的开源书籍，提供在线互动版本。
    - **链接**：[英文官网](https://d2l.ai/)（个人推荐读英文原版，中文版质量感觉略逊于英文，当然你也可以在网站中切换到中文）

#### **2. 概念与原理的直观理解 (可视化工具)**

- **3Blue1Brown 关于神经网络的系列视频**
    - **简介**：如果你对神经网络背后的数学原理还感觉有些抽象，这个系列视频是最好的可视化入门材料。它通过精妙的动画，将梯度下降、反向传播等核心概念解释得淋漓尽致。
    - **链接**：[Bilibili 中文翻译版](https://www.bilibili.com/video/BV1bx411M7Zx/?spm_id_from=333.337.search-card.all.click&vd_source=730edf386f1ddaf0924e407c157d2b78)
- **CNN Explainer (CNN 解释器)**
    - **简介**：一个交互式的网站，逐层可视化了一个小型CNN处理手写数字的全过程。你可以看到卷积核是如何滑动的，ReLU是如何激活的，池化是如何降维的，数据在每一层的形状变化一目了然
    - **链接**：[CNN Explainer 官网](https://poloclub.github.io/cnn-explainer/)

#### **3. 经典学术论文**

- **AlexNet**: *ImageNet Classification with Deep Convolutional Neural Networks*
    - **简介**：在ImageNet竞赛中取得突破性成功，引爆了深度学习在学术界和工业界的浪潮。它首次成功应用了ReLU、Dropout等我们今天熟知的技术。
    - 链接：https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
- **ViT:** *An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale*
    - **简介**: 与cnn不同，ViT开创了使用transformer进行图像分类的时代，为整个CV领域带来了transformer热潮（
    - 链接：https://arxiv.org/abs/2010.11929



## 4 注意力

*出题人：梁栢杰*

本题围绕自注意力机制的核心概念、实现方法及应用展开，考查对该机制的理解与实践能力。

### 小题1：概念与公式阐述

1. **词嵌入（Word Embedding）**：
    - 请解释词嵌入的定义及其作用。
    - 说明词嵌入如何解决传统词表示方法的局限性。
    - 举例说明一种常见的词嵌入模型及其特点。
2. **多头自注意力（Multi-Head Self-Attention）**：
    - 说明多头自注意力的核心思想
    - 写出缩放点积注意力（Scaled Dot-Product Attention）的计算公式，并解释公式中各参数的含义。

### 小题2：基于NumPy手动实现多头自注意力

要求：使用纯NumPy实现多头自注意力机制，需固定随机种子以保证结果可复现，遵循以下步骤完成代码编写。

1. 基础函数实现：
    - 完善`scaled_dot_product_attention`函数，要求：
        - 输入参数为Q（查询）、K（键）、V（值）和可选的mask
        - 输出为注意力加权后的向量和注意力权重矩阵
2. 多头注意力实现：
    - 完善`multi_head_attention`函数，要求：
        - 输入参数为嵌入维度（embed_size）、头数（num_heads）、输入序列（input）和可选的mask
        - 随机初始化4个线性变换矩阵（Wq、Wk、Wv、Wo）
        - 输出最终注意力向量和注意力权重（可返回任意一个头的权重用于验证）
3. 测试验证：
    - 使用固定随机种子（np.random.seed(114514)）
    - 构造测试输入：batch_size=10，seq_len=20，embed_size=128
    - 调用`multi_head_attention`（num_heads=8），打印输出向量的形状和注意力权重的形状
    - 抽取输出向量中(0,0,0~10)位置的数值进行打印

```python
import numpy as np

np.random.seed(114514)

def scaled_dot_product_attention(Q, K, V, mask=None):

    return output, attention_weights

def multi_head_attention(embed_size, num_heads, input, mask=None):

    return output, weights

if __name__ == "__main__":
  batch_size = 10
  seq_len = 20
	embed_size = 128
	num_heads = 8
	input = np.random.randn(batch_size, seq_len, embed_size) 
	output, weights = multi_head_attention(embed_size, num_heads, input)
	
	print(output.shape, weights.shape)
	print(output[0][0][:10], weights[0][0][0][:10])

```

### 小题3：基于PyTorch实现多头自注意力机制

要求：使用PyTorch框架及其内置模块实现多头自注意力机制

1. 模型实现：
    - 定义一个`MultiHeadAttention`类，继承自`torch.nn.Module`
    - 初始化参数包括：嵌入维度（embed_size）、头数（num_heads）、 dropout概率
    - 在`__init__`方法中：
        - 验证嵌入维度与头数的兼容性
        - 使用`nn.Linear`定义Q、K、V的线性变换层和输出线性层
        - 定义dropout层
    - 类似任务2，实现`scaled_dot_product_attention`方法：
        - 计算自注意力
    - 实现`forward`方法：
        - 输入参数为query、key、value和可选的mask
        - 使用PyTorch自定义实现计算注意力
        - 返回最终输出和注意力权重

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class MultiHeadAttention(nn.Module):
    """基于PyTorch的多头自注意力实现"""
    def __init__(self, embed_size, num_heads, dropout=0.1):
        super().__init__()
        pass
        
		def scaled_dot_product_attention(self, Q, K, V, mask=None):
		
				pass
				
    def forward(self, query, key, value, mask=None):

        pass

# 测试代码
if __name__ == "__main__":
    # 构造测试输入（与任务2保持一致的形状）
    batch_size = 10
    seq_len = 20
    embed_size = 128
    num_heads = 8
    
    input_tensor = torch.randn(batch_size, seq_len, embed_size)
    model = MultiHeadAttention(embed_size, num_heads)

    # 执行自注意力计算（query=key=value）
    output, attn_weights = model(input_tensor, input_tensor, input_tensor)

    print(output.shape, weights.shape)
    print(output[0][0][:10], weights[0][0][0][:10])

```

### 小题4：注意力机制的其他应用（可选）

**视觉领域的注意力机制应用**：

Vision Transformer (ViT) 成功地将自注意力机制应用于计算机视觉任务。请围绕其核心思想，扼要回答以下几个关键点：

- **图像的序列化处理**：
自注意力机制最初用于处理一维序列（如文本）。请说明ViT是如何将二维图像转换为Transformer模型可以处理的一维向量序列的？
- **空间位置信息的编码**：
标准的自注意力机制不包含输入的顺序信息。请说明ViT是如何为图像块（Patches）添加空间位置信息，以弥补这一点的？
- **与CNN的核心区别与优势**：
与经典的卷积神经网络（CNN）相比，ViT所使用的自注意力机制在处理图像时，其最主要的优势是什么

### **相关学习资源**

为了帮助你更好地完成本题并深入理解相关概念，我们推荐以下学习资料：

#### **核心概念**

- **必读论文：《Attention Is All You Need》**
    - **简介**: Transformer和自注意力机制的开山之作，是理解本题所有概念的源头。
    - **资源链接**: https://arxiv.org/abs/1706.03762
- **图解文章：《The Illustrated Transformer》 by Jay Alammar**
    - **简介**: 这篇博客用极其生动和可视化的方式解释了Transformer和自注意力的工作原理，非常适合初学者建立直观理解。
    - **资源链接**: http://jalammar.github.io/illustrated-transformer/
- **图解文章：《The Illustrated Word2vec》 by Jay Alammar**
    - **简介**: 详细解释了Word2Vec的工作原理，有助于深入理解词嵌入。
    - **资源链接**: http://jalammar.github.io/illustrated-word2vec/

#### **扩展应用与优化**

- **视觉Transformer论文：《An Image is Worth 16x16 Words》**
    - **简介**: 视觉Transformer（ViT）的开创性工作，介绍了如何将标准Transformer直接应用于图像分类任务。
    - **资源链接**: https://arxiv.org/abs/2010.11929


## 5 库调用

*出题人：郭际泽*

本题考查你自主学习使用前沿技术的能力。在本题中，**不要求你对使用的算法和技术有任何原理上的了解**，只需正确调用相关的库或 API 完成任务即可。

本题的题目描述较为简略，你需要自行利用搜索、AI 等方式找到所需功能所在的位置。不必害怕题面中陌生的概念，它们并不难理解。

在完成任务的过程中，你可以顺手记录一些对你比较有帮助的网页链接，或者是遇到的报错信息及解决方式。对这一部分的详细程度不作要求，但这能使我们相信你没有用 AI 直接生成整道题的答案。

---

2021 年初，OpenAI 公布了 [CLIP](https://openai.com/index/clip)。这个模型在大量图像-文本对上训练，具有将图像与文本对应起来的能力。这一类模型既能单独用于图像分类等任务，也经常作为多模态 LLM 的组件出现。

### 小题1

部署 [google/siglip2-base-patch16-224](https://huggingface.co/google/siglip2-base-patch16-224)（下文简称 SigLIP）到本地。

运行该仓库 README 中的第一段示例代码，并汇报结果。此外，请简要描述本节中你配置开发环境的过程。

提示：你可能需要 [HF-Mirror](https://hf-mirror.com/)。

### 小题2

在接下来的实验中，我们会使用 [ethz/food101](https://huggingface.co/datasets/ethz/food101)（下文简称 food101）数据集。

使用 SigLIP 的 zero-shot classification 功能在 food101 的验证集上（每类取**前 10 张**图，共 1010 张）测试 top-5 准确率。

提示：数据集的 README 中可以找到标签 ID 与标签文本的对应。

### 小题3

SigLIP 还可以用来生成 embedding。

在 food101 的训练集上选取以下 5 类图片的**前 100 张**，共 500 张：

- `pizza`
- `sushi`
- `hamburger`
- `ice_cream`
- `dumplings`

生成这些图片的 embedding，使用 UMAP 降维到 2 维并绘图展示。

### 小题4

在 SigLIP 生成的 embedding 的基础上，训练一个 linear probing 层实现任务 2 中的食品分类任务。

使用训练集中每类图片的**第 1 张**（共 101 张）进行训练，训练 100 个 epoch。训练过程中建议使用 tensorboard 或类似工具记录 loss 曲线，并在结果中附图展示。

准确率和任务 2 中相比如何？

Bonus: 使用 data augmentation 能否提升准确率？为什么？

提示：学习率是一个重要的超参数，你需要确定其合适的数量级。

### 小题5


调用 Gemini 2.5 Flash 的 API 实现任务 2 中的食品分类任务。准确率和任务 2 中相比如何？

Bonus: 使用异步 IO 以提升 API 调用效率。

提示：你可能需要设计一个 prompt 以便于从 LLM 的回复中提取答案，也可以配合 structured output。API 消耗金钱，请不要过度浪费。具体的api配置如下：

```python
import os

os.environ["OPENAI_API_KEY"]="sk-yxhm7vIgkeffD0FU1bE5F797B654482d94CbB6DbBa556b96"
os.environ["OPENAI_BASE_URL"]="https://api.ai-gaochao.cn/v1"

```

## 提交要求

​		最终提交`.zip`**压缩包**文件，命名为**年级-学院-姓名**的格式。例如，来自计算机学院的21级的张三提交文件描述如下：

```
|── 21-CS-张三
|   ├── 1
|   ├── 2
|   ├── 3
|   ├── 4
|   ├── 5

```

​	  你需要提交对应的**代码文件**、**说明文档**、图片文件（若有）和其他文件（若有）。 

​		注意，若你使用Markdown文件作为说明文档，请注意将所用的图片文件路径更改为相对路径，若最终提交的显示效果有误，我们不会为你改正。

​		请在**2025年9月15日00:00:00**前。将个人文件提交至[此链接](https://send2me.cn/0WmaryZE/T0K9Tc4tsRcjgA)。